{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import io\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_APPLICATION_CREDENTIALS: /workspaces/financial_data_scraping/jaber-financial-b20f23e23588.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the environment variable for the Google Cloud credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/workspaces/financial_data_scraping/jaber-financial-b20f23e23588.json'\n",
    "\n",
    "# Verify that it has been set correctly\n",
    "print(\"GOOGLE_APPLICATION_CREDENTIALS:\", os.getenv('GOOGLE_APPLICATION_CREDENTIALS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'companies_details' exists: True\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def test_gcs_access(bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' exists: {bucket.exists()}\")\n",
    "\n",
    "# Replace 'your-bucket-name' with your actual bucket name\n",
    "test_gcs_access('companies_details')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Google Cloud Storage bucket name and file path\n",
    "bucket_name = 'companies_details'\n",
    "source_blob_name = 'data/companies_details.parquet'\n",
    "\n",
    "def download_from_gcs(bucket_name, source_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    file_content = blob.download_as_bytes()\n",
    "    return file_content\n",
    "\n",
    "# Download the file content from GCS\n",
    "file_content = download_from_gcs(bucket_name, source_blob_name)\n",
    "\n",
    "# Load the content into a pandas DataFrame\n",
    "all_companies = pd.read_parquet(io.BytesIO(file_content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to data/analyst_price_target.parquet in bucket analyst_price_target.\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch price targets\n",
    "def fetch_price_targets(ticker, isin):\n",
    "    try:\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        info = ticker_data.info\n",
    "\n",
    "        return {\n",
    "            'ISIN': isin,\n",
    "            'Ticker': ticker,\n",
    "            'Current': info.get('currentPrice'),\n",
    "            'Average': info.get('targetMeanPrice'),\n",
    "            'High': info.get('targetHighPrice'),\n",
    "            'Low': info.get('targetLowPrice'),\n",
    "            'scraping_url_analysis': f\"https://finance.yahoo.com/quote/{ticker}/analysis/\",\n",
    "            'scraping_timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "# List of tickers from the DataFrame\n",
    "tickers = all_companies[['Ticker', 'ISIN']].values.tolist()\n",
    "\n",
    "# Fetch price targets for each ticker with a delay\n",
    "analyst_price_target = []\n",
    "for ticker, isin in tickers:\n",
    "    price_data = fetch_price_targets(f\"{ticker}.MC\", isin)\n",
    "    if price_data:\n",
    "        analyst_price_target.append(price_data)\n",
    "\n",
    "    # Introduce random delay between API calls (1 to 3 seconds)\n",
    "    random_int = np.random.choice([1, 2, 3])\n",
    "    time.sleep(random_int)\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "analyst_price_target = pd.DataFrame(analyst_price_target)\n",
    "\n",
    "# Function to upload DataFrame to GCS\n",
    "def upload_to_gcs(bucket_name, df, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Convert DataFrame to a BytesIO buffer\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Upload the buffer to GCS\n",
    "    blob.upload_from_file(buffer, content_type='application/octet-stream')\n",
    "    print(f\"Data uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n",
    "\n",
    "# Define Google Cloud Storage bucket name and file path\n",
    "bucket_name = 'analyst_price_target'\n",
    "destination_blob_name = 'data/analyst_price_target.parquet'\n",
    "\n",
    "# Upload to GCS\n",
    "upload_to_gcs(bucket_name, analyst_price_target, destination_blob_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved locally to /workspaces/financial_data_scraping/data/analyst_price_target.parquet.\n",
      "Data uploaded to data/analyst_price_target.parquet in bucket analyst_price_target.\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch price targets\n",
    "def fetch_price_targets(ticker, isin):\n",
    "    try:\n",
    "        ticker_data = yf.Ticker(ticker)\n",
    "        info = ticker_data.info\n",
    "\n",
    "        return {\n",
    "            'ISIN': isin,\n",
    "            'Ticker': ticker,\n",
    "            'Current': info.get('currentPrice'),\n",
    "            'Average': info.get('targetMeanPrice'),\n",
    "            'High': info.get('targetHighPrice'),\n",
    "            'Low': info.get('targetLowPrice'),\n",
    "            'scraping_url_analysis': f\"https://finance.yahoo.com/quote/{ticker}/analysis/\",\n",
    "            'scraping_timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to upload DataFrame to GCS\n",
    "def upload_to_gcs(bucket_name, df, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Convert DataFrame to a BytesIO buffer\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_parquet(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Upload the buffer to GCS\n",
    "    blob.upload_from_file(buffer, content_type='application/octet-stream')\n",
    "    print(f\"Data uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n",
    "\n",
    "# Function to save DataFrame locally\n",
    "def save_locally(df, local_path):\n",
    "    df.to_parquet(local_path, index=False)\n",
    "    print(f\"Data saved locally to {local_path}.\")\n",
    "\n",
    "# List of tickers from the DataFrame\n",
    "tickers = all_companies[['Ticker', 'ISIN']].values.tolist()\n",
    "\n",
    "# Fetch price targets for each ticker with a delay\n",
    "analyst_price_target = []\n",
    "for ticker, isin in tickers:\n",
    "    price_data = fetch_price_targets(f\"{ticker}.MC\", isin)\n",
    "    if price_data:\n",
    "        analyst_price_target.append(price_data)\n",
    "\n",
    "    # Introduce random delay between API calls (1 to 3 seconds)\n",
    "    random_int = np.random.choice([1, 2, 3])\n",
    "    time.sleep(random_int)\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "analyst_price_target = pd.DataFrame(analyst_price_target)\n",
    "\n",
    "# Define Google Cloud Storage bucket name and file path\n",
    "bucket_name = 'analyst_price_target'\n",
    "destination_blob_name = 'data/analyst_price_target.parquet'\n",
    "\n",
    "# Define local file path\n",
    "local_file_path = '/workspaces/financial_data_scraping/data/analyst_price_target.parquet'\n",
    "\n",
    "# Ensure the local directory exists\n",
    "local_dir = os.path.dirname(local_file_path)\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "# Save DataFrame locally\n",
    "save_locally(analyst_price_target, local_file_path)\n",
    "\n",
    "# Upload to GCS\n",
    "upload_to_gcs(bucket_name, analyst_price_target, destination_blob_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
